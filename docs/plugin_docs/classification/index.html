<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Classification - OpenBR</title>
  

  <link rel="shortcut icon" href="../../docs/img/openbr.ico">
  

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../../css/highlight.css">

  <script src="../../js/jquery-2.1.1.min.js"></script>
  <script src="../../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../../js/highlight.pack.js"></script>
  <script src="../../js/theme.js"></script> 

  
</head>

<body class="wy-body-for-nav" role="document">
    <div class="wy-grid-for-nav">
        
        <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
            <div class="wy-side-nav-search">
                <a href="../.." class="icon icon-home"> OpenBR</a>
                <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
            </div>

            <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul class="current">
                    
                        <li><ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../..">Home</a>
        </li>
        
    
</ul><li>
                    
                        <li><ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../../install/">Install</a>
        </li>
        
    
</ul><li>
                    
                        <li><ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../../tutorials/">Tutorials</a>
        </li>
        
    
</ul><li>
                    
                        <li><ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../../contribute/">Contribute</a>
        </li>
        
    
</ul><li>
                    
                        <li><ul class="subnav">
    
        
            <li><span>API Documentation</span></li>
            
                <ul class="subnav">
    
        
            <li class="l1 ">
                <a href="../../api_docs/c_api/">C API</a>
            </li>
            
        
    
</ul>
            
                <ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../../api_docs/cl_api/">Command Line API</a>
        </li>
        
    
</ul>
            
                <ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../../api_docs/python_api/">Python Wrapper API</a>
        </li>
        
    
</ul>
            
                <ul class="subnav">
    
        
            <li class="l1 ">
                <a href="../../api_docs/cpp_api/">C++ Plugin API</a>
            </li>
            
        
    
</ul>
            
        
    
</ul><li>
                    
                        <li><ul class="subnav">
    
        
            <li><span>Plugin Documentation</span></li>
            
                <ul class="subnav">
    
        <li class="l1 current">
            <a class="current" href="./">Classification</a>
        </li>
        
            <ul class="subnav">
                
                    <li><a href="#adaboosttransform">AdaBoostTransform</a></li>
                
                    <li><a href="#boostedforestclassifier">BoostedForestClassifier</a></li>
                
                    <li><a href="#cascadeclassifier">CascadeClassifier</a></li>
                
                    <li><a href="#dffstransform">DFFSTransform</a></li>
                
                    <li><a href="#dlibshaperesourcemaker">DLibShapeResourceMaker</a></li>
                
                    <li><a href="#dobjectdetectortransform">DObjectDetectorTransform</a></li>
                
                    <li><a href="#ebiftransform">EBIFTransform</a></li>
                
                    <li><a href="#forestinductiontransform">ForestInductionTransform</a></li>
                
                    <li><a href="#foresttransform">ForestTransform</a></li>
                
                    <li><a href="#ipc2013facerecognitiontransform">IPC2013FaceRecognitionTransform</a></li>
                
                    <li><a href="#ldatransform">LDATransform</a></li>
                
                    <li><a href="#linear">Linear</a></li>
                
                    <li><a href="#mlptransform">MLPTransform</a></li>
                
                    <li><a href="#nt4compare">NT4Compare</a></li>
                
                    <li><a href="#nt4detectface">NT4DetectFace</a></li>
                
                    <li><a href="#nt4enrollface">NT4EnrollFace</a></li>
                
                    <li><a href="#nt4enrolliris">NT4EnrollIris</a></li>
                
                    <li><a href="#pcatransform">PCATransform</a></li>
                
                    <li><a href="#pp4compare">PP4Compare</a></li>
                
                    <li><a href="#pp4enrolltransform">PP4EnrollTransform</a></li>
                
                    <li><a href="#pp5comparedistance">PP5CompareDistance</a></li>
                
                    <li><a href="#pp5enrolltransform">PP5EnrollTransform</a></li>
                
                    <li><a href="#pp5gallerytransform">PP5GalleryTransform</a></li>
                
                    <li><a href="#svmtransform">SVMTransform</a></li>
                
                    <li><a href="#sparseldatransform">SparseLDATransform</a></li>
                
                    <li><a href="#turkclassifiertransform">TurkClassifierTransform</a></li>
                
                    <li><a href="#wcdatransform">WCDATransform</a></li>
                
            </ul>
        
    
</ul>
            
                <ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../cluster/">Cluster</a>
        </li>
        
    
</ul>
            
                <ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../core/">Core</a>
        </li>
        
    
</ul>
            
                <ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../distance/">Distance</a>
        </li>
        
    
</ul>
            
                <ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../format/">Format</a>
        </li>
        
    
</ul>
            
                <ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../gallery/">Gallery</a>
        </li>
        
    
</ul>
            
                <ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../gui/">GUI</a>
        </li>
        
    
</ul>
            
                <ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../imgproc/">Image Processing</a>
        </li>
        
    
</ul>
            
                <ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../io/">I/O</a>
        </li>
        
    
</ul>
            
                <ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../metadata/">Metadata</a>
        </li>
        
    
</ul>
            
                <ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../output/">Output</a>
        </li>
        
    
</ul>
            
                <ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../representation/">Representation</a>
        </li>
        
    
</ul>
            
                <ul class="subnav">
    
        <li class="l1 ">
            <a class="" href="../video/">Video</a>
        </li>
        
    
</ul>
            
        
    
</ul><li>
                    
                </ul>
            </div>
            &nbsp;
        </nav>

        <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
            
            <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
                <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
                <a href="../..">OpenBR</a>
            </nav>

            
            <div class="wy-nav-content">
                <div class="rst-content">
                    <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Plugin Documentation &raquo;</li>
        
      
    
    <li>Classification</li>
    <li class="wy-breadcrumbs-aside">
      
        
          <a href="https://github.com/biometrics/openbr" class="icon icon-github"> Edit on GitHub</a>
        
      
    </li>
  </ul>
  <hr/>
</div>

                    <div role="main">
                        <div class="section">
                            
                                <!--<div class="toc" data-spy="affix" role="navigation" aria-label="main navigation">
                                    <ul class="current">
                                        <span>Table of Contents</span>
                                        <ul>
                                            
                                                <li><a href="#adaboosttransform"><span>AdaBoostTransform</span></a></li>
                                            
                                                <li><a href="#boostedforestclassifier"><span>BoostedForestClassifier</span></a></li>
                                            
                                                <li><a href="#cascadeclassifier"><span>CascadeClassifier</span></a></li>
                                            
                                                <li><a href="#dffstransform"><span>DFFSTransform</span></a></li>
                                            
                                                <li><a href="#dlibshaperesourcemaker"><span>DLibShapeResourceMaker</span></a></li>
                                            
                                                <li><a href="#dobjectdetectortransform"><span>DObjectDetectorTransform</span></a></li>
                                            
                                                <li><a href="#ebiftransform"><span>EBIFTransform</span></a></li>
                                            
                                                <li><a href="#forestinductiontransform"><span>ForestInductionTransform</span></a></li>
                                            
                                                <li><a href="#foresttransform"><span>ForestTransform</span></a></li>
                                            
                                                <li><a href="#ipc2013facerecognitiontransform"><span>IPC2013FaceRecognitionTransform</span></a></li>
                                            
                                                <li><a href="#ldatransform"><span>LDATransform</span></a></li>
                                            
                                                <li><a href="#linear"><span>Linear</span></a></li>
                                            
                                                <li><a href="#mlptransform"><span>MLPTransform</span></a></li>
                                            
                                                <li><a href="#nt4compare"><span>NT4Compare</span></a></li>
                                            
                                                <li><a href="#nt4detectface"><span>NT4DetectFace</span></a></li>
                                            
                                                <li><a href="#nt4enrollface"><span>NT4EnrollFace</span></a></li>
                                            
                                                <li><a href="#nt4enrolliris"><span>NT4EnrollIris</span></a></li>
                                            
                                                <li><a href="#pcatransform"><span>PCATransform</span></a></li>
                                            
                                                <li><a href="#pp4compare"><span>PP4Compare</span></a></li>
                                            
                                                <li><a href="#pp4enrolltransform"><span>PP4EnrollTransform</span></a></li>
                                            
                                                <li><a href="#pp5comparedistance"><span>PP5CompareDistance</span></a></li>
                                            
                                                <li><a href="#pp5enrolltransform"><span>PP5EnrollTransform</span></a></li>
                                            
                                                <li><a href="#pp5gallerytransform"><span>PP5GalleryTransform</span></a></li>
                                            
                                                <li><a href="#svmtransform"><span>SVMTransform</span></a></li>
                                            
                                                <li><a href="#sparseldatransform"><span>SparseLDATransform</span></a></li>
                                            
                                                <li><a href="#turkclassifiertransform"><span>TurkClassifierTransform</span></a></li>
                                            
                                                <li><a href="#wcdatransform"><span>WCDATransform</span></a></li>
                                            
                                        </ul>
                                    </ul>
                                </div>-->
                                <h1 id="adaboosttransform">AdaBoostTransform</h1>
<p>Wraps OpenCV's Ada Boost framework</p>
<ul>
<li><strong>file:</strong> classification/adaboost.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/transform/transform/">Transform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/sklum" title="Scott J. Klum scott.klum@gmail.com">Scott Klum</a></li>
<li><strong>see:</strong> <a href="http://docs.opencv.org/modules/ml/doc/boosting.html"></a></li>
<li>
<p><strong>properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>enum</td>
<td>type</td>
<td>Type of Adaboost to perform. Options are:<ul><li>Discrete</li><li>Real</li><li>Logit</li><li>Gentle</li></ul>Default is Real.</td>
</tr>
<tr>
<td>enum</td>
<td>splitCriteria</td>
<td>Splitting criteria used to choose optimal splits during a weak tree construction. Options are:<ul><li>Default</li><li>Gini</li><li>Misclass</li><li>Sqerr</li></ul>Default is Default.</td>
</tr>
<tr>
<td>int</td>
<td>weakCount</td>
<td>Maximum number of weak classifiers per stage. Default is 100.</td>
</tr>
<tr>
<td>float</td>
<td>trimRate</td>
<td>A threshold between 0 and 1 used to save computational time. Samples with summary weight</td>
</tr>
<tr>
<td>int</td>
<td>folds</td>
<td>OpenCV parameter variable. Default value is 0.</td>
</tr>
<tr>
<td>int</td>
<td>maxDepth</td>
<td>Maximum height of each weak classifier tree. Default is 1 (stumps).</td>
</tr>
<tr>
<td>bool</td>
<td>returnConfidence</td>
<td>Return the confidence value of the classification or the class value of the classification. Default is true (return confidence value).</td>
</tr>
<tr>
<td>bool</td>
<td>overwriteMat</td>
<td>If true, the output template will be a 1x1 matrix with value equal to the confidence or classification (depending on returnConfidence). If false the output template will be the same as the input template. Default is true.</td>
</tr>
<tr>
<td>QString</td>
<td>inputVariable</td>
<td>Metadata variable storing the label for each template. Default is "Label".</td>
</tr>
<tr>
<td>QString</td>
<td>outputVariable</td>
<td>Metadata variable to store the confidence or classification of each template (depending on returnConfidence). If overwriteMat is true nothing will be written here. Default is "".</td>
</tr>
</tbody>
</table>
</li>
</ul>
<hr />
<h1 id="boostedforestclassifier">BoostedForestClassifier</h1>
<p>A classification wrapper on OpenCV's CvBoost class. It uses CvBoost for training a boosted forest and then performs classification using the trained nodes.</p>
<ul>
<li><strong>file:</strong> classification/boostedforest.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/classifier/classifier/">Classifier</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/JordanCheney" title="Jordan Cheney jordan.cheney@gmail.com">Jordan Cheney</a>, <a href="https://github.com/sklum" title="Scott J. Klum scott.klum@gmail.com">Scott Klum</a></li>
<li>
<p><strong>properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>representation</td>
<td>Representation*</td>
<td>The Representation describing the features used by the boosted forest</td>
</tr>
<tr>
<td>minTAR</td>
<td>float</td>
<td>The minimum true accept rate during training</td>
</tr>
<tr>
<td>maxFAR</td>
<td>float</td>
<td>The maximum false accept rate during training</td>
</tr>
<tr>
<td>trimRate</td>
<td>float</td>
<td>The trim rate during training</td>
</tr>
<tr>
<td>maxDepth</td>
<td>int</td>
<td>The maximum depth for each trained tree</td>
</tr>
<tr>
<td>maxWeakCount</td>
<td>int</td>
<td>The maximum number of trees in the forest</td>
</tr>
<tr>
<td>type.</td>
<td>Type</td>
<td>The type of boosting to perform. Options are<ul><li>Discrete</li><li>Real</li><li>Logit</li><li>Gentle</li></ul>. Gentle is the default.</td>
</tr>
</tbody>
</table>
</li>
</ul>
<hr />
<h1 id="cascadeclassifier">CascadeClassifier</h1>
<p>A meta <a href="../../api_docs/cpp_api/classifier/classifier/">Classifier</a> that creates a cascade of another <a href="../../api_docs/cpp_api/classifier/classifier/">Classifier</a>. The cascade is a series of stages, each with its own instance of a given classifier. A sample can only reach the next stage if it is classified as positive by the previous stage.</p>
<ul>
<li><strong>file:</strong> classification/cascade.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/classifier/classifier/">Classifier</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/JordanCheney" title="Jordan Cheney jordan.cheney@gmail.com">Jordan Cheney</a>, <a href="https://github.com/sklum" title="Scott J. Klum scott.klum@gmail.com">Scott Klum</a></li>
<li><strong>see:</strong> <a href="https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf">Rapid Object Detection using a Boosted Cascade of Simple Features</a></li>
<li>
<p><strong>read:</strong></p>
<ol>
<li><em>Paul Viola, Michael Jones</em><br>
 <strong>Rapid Object Detection using a Boosted Cascade of Simple Features</strong>
 CVPR, 2001</li>
</ol>
</li>
<li>
<p><strong>properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>numStages</td>
<td>int</td>
<td>The number of stages in the cascade</td>
</tr>
<tr>
<td>numPos</td>
<td>int</td>
<td>The number of positives to feed each stage during training</td>
</tr>
<tr>
<td>numNegs</td>
<td>int</td>
<td>The number of negatives to feed each stage during training. A negative sample must have been classified by the previous stages in the cascade as positive to be fed to the next stage during training.</td>
</tr>
<tr>
<td>maxFAR</td>
<td>float</td>
<td>A termination parameter. Calculated as (number of passed negatives) / (total number of checked negatives) for a given stage during training. If that number is below the given maxFAR cascade training is terminated early. This can help prevent overfitting.</td>
</tr>
</tbody>
</table>
</li>
</ul>
<hr />
<h1 id="dffstransform">DFFSTransform</h1>
<p>Computes <a href="../../api_docs/cpp_api/distance/distance/">Distance</a> From Feature Space (DFFS)</p>
<ul>
<li><strong>file:</strong> classification/lda.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/transform/transform/">Transform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/jklontz" title="Joshua C. Klontz, jklontz@ieee.org">Josh Klontz</a></li>
<li>
<p><strong>read:</strong></p>
<ol>
<li><em>Moghaddam, Baback, and Alex Pentland.</em><br>
 <strong>"Probabilistic visual learning for object representation."</strong>
 Pattern Analysis and Machine Intelligence, IEEE Transactions on 19.7 (1997): 696-710.</li>
</ol>
</li>
<li>
<p><strong>properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>keep</td>
<td>float</td>
<td>Sets PCA keep property. Default is 0.95.</td>
</tr>
</tbody>
</table>
</li>
</ul>
<hr />
<h1 id="dlibshaperesourcemaker">DLibShapeResourceMaker</h1>
<p>Wrapper to dlib's landmarker.</p>
<ul>
<li><strong>file:</strong> classification/dlib.cpp</li>
<li><strong>inherits:</strong> <a href="#resourcemaker&lt;shape_predictor&gt;">ResourceMaker<shape_predictor></a></li>
<li><strong>author(s):</strong> <a href="https://github.com/sklum" title="Scott J. Klum scott.klum@gmail.com">Scott Klum</a></li>
<li><strong>properties:</strong> None</li>
</ul>
<hr />
<h1 id="dobjectdetectortransform">DObjectDetectorTransform</h1>
<p>Wrapper to dlib's trainable object detector.</p>
<ul>
<li><strong>file:</strong> classification/dlib.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/transform/transform/">Transform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/sklum" title="Scott J. Klum scott.klum@gmail.com">Scott Klum</a></li>
<li><strong>properties:</strong> None</li>
</ul>
<hr />
<h1 id="ebiftransform">EBIFTransform</h1>
<p>Face Recognition Using Early Biologically Inspired Features</p>
<ul>
<li><strong>file:</strong> classification/ebif.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/untrainabletransform/untrainabletransform/">UntrainableTransform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/jklontz" title="Joshua C. Klontz, jklontz@ieee.org">Josh Klontz</a></li>
<li>
<p><strong>read:</strong></p>
<ol>
<li><em>Li, Min, et al.</em><br>
 <strong>"Face recognition using early biologically inspired features."</strong>
 Biometrics: Theory, Applications and Systems (BTAS), 2013 IEEE Sixth International Conference on. IEEE, 2013.</li>
</ol>
</li>
<li>
<p><strong>properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>N</td>
<td>int</td>
<td>The number of scales. Default is 6.</td>
</tr>
<tr>
<td>M</td>
<td>int</td>
<td>The number of orientations between 0 and pi. Default is 9.</td>
</tr>
</tbody>
</table>
</li>
</ul>
<hr />
<h1 id="forestinductiontransform">ForestInductionTransform</h1>
<p>Wraps OpenCV's random trees framework to induce features</p>
<ul>
<li><strong>file:</strong> classification/forest.cpp</li>
<li><strong>inherits:</strong> <a href="#foresttransform">ForestTransform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/sklum" title="Scott J. Klum scott.klum@gmail.com">Scott Klum</a></li>
<li><strong>see:</strong> <a href="https://lirias.kuleuven.be/bitstream/123456789/316661/1/icdm11-camready.pdf"></a></li>
<li>
<p><strong>properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>useRegressionValue</td>
<td>bool</td>
<td>SCOTT FILL ME IN.</td>
</tr>
</tbody>
</table>
</li>
</ul>
<hr />
<h1 id="foresttransform">ForestTransform</h1>
<p>Wraps OpenCV's random trees framework</p>
<ul>
<li><strong>file:</strong> classification/forest.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/transform/transform/">Transform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/sklum" title="Scott J. Klum scott.klum@gmail.com">Scott Klum</a></li>
<li><strong>see:</strong> <a href="http://docs.opencv.org/modules/ml/doc/random_trees.html"></a></li>
<li>
<p><strong>properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>classification</td>
<td>bool</td>
<td>If true the labels are expected to be categorical. Otherwise they are expected to be numerical. Default is true.</td>
</tr>
<tr>
<td>splitPercentage</td>
<td>float</td>
<td>Used to calculate the minimum number of samples per split in a random tree. The minimum number of samples is calculated as the number of samples x splitPercentage. Default is 0.01.</td>
</tr>
<tr>
<td>maxDepth</td>
<td>int</td>
<td>The maximum depth of each decision tree. Default is std::numeric_limits<int>::max() and typically should be set by the user.</td>
</tr>
<tr>
<td>maxTrees</td>
<td>int</td>
<td>The maximum number of trees in the forest. Default is 10.</td>
</tr>
<tr>
<td>forestAccuracy</td>
<td>float</td>
<td>A sufficient accuracy for the forest for training to terminate. Used if termCrit is EPS or Both. Default is 0.1.</td>
</tr>
<tr>
<td>returnConfidence</td>
<td>bool</td>
<td>If both classification and returnConfidence are use a fuzzy class label as the output of the forest. Default is true.</td>
</tr>
<tr>
<td>overwriteMat</td>
<td>bool</td>
<td>If true set dst to be a 1x1 Mat with the forest response as its value. Otherwise append the forest response to metadata using outputVariable as a key. Default is true.</td>
</tr>
<tr>
<td>inputVariable</td>
<td>QString</td>
<td>The metadata key for each templates label. Default is "Label".</td>
</tr>
<tr>
<td>outputVariable</td>
<td>QString</td>
<td>The metadata key for the forest response if overwriteMat is false. Default is "".</td>
</tr>
<tr>
<td>weight</td>
<td>bool</td>
<td>If true and classification is true the random forest will use prior accuracies. Default is false.</td>
</tr>
<tr>
<td>termCrit</td>
<td>enum</td>
<td>Termination criteria for training the random forest. Options are Iter, EPS and Both. Iter terminates when the maximum number of trees is reached. EPS terminates when forestAccuracy is met. Both terminates when either is true. Default is Iter.</td>
</tr>
</tbody>
</table>
</li>
</ul>
<hr />
<h1 id="ipc2013facerecognitiontransform">IPC2013FaceRecognitionTransform</h1>
<p>Intel Perceptual Computing SDK 2013 Face Recognition</p>
<ul>
<li><strong>file:</strong> classification/ipc2013.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/untrainabletransform/untrainabletransform/">UntrainableTransform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/jklontz" title="Joshua C. Klontz, jklontz@ieee.org">Josh Klontz</a></li>
<li><strong>properties:</strong> None</li>
</ul>
<hr />
<h1 id="ldatransform">LDATransform</h1>
<p>Projects input into learned Linear Discriminant Analysis subspace.</p>
<ul>
<li><strong>file:</strong> classification/lda.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/transform/transform/">Transform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/bklare" title="Dr. Brendan F. Klare brendan.klare@ieee.org">Brendan Klare</a>, <a href="https://github.com/jklontz" title="Joshua C. Klontz, jklontz@ieee.org">Josh Klontz</a></li>
<li>
<p><strong>properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>pcaKeep</td>
<td>float</td>
<td>If &lt;= 1, the percentage of variance to retain in initial PCA step. If &gt; 1, the number of dimensions to keep.</td>
</tr>
<tr>
<td>pcaWhiten</td>
<td>bool</td>
<td>Whether or not to perform whitening during PCA step</td>
</tr>
<tr>
<td>directLDA</td>
<td>int</td>
<td>Whether or not to use the Direct LDA algorithm.</td>
</tr>
<tr>
<td>directDrop</td>
<td>float</td>
<td>Parameter for Direct LDA to specify how many leading vectors in within class matrix to drop. Based on variance.</td>
</tr>
<tr>
<td>inputVariable</td>
<td>QString</td>
<td>Metadata key for subject labels.</td>
</tr>
<tr>
<td>isBinary</td>
<td>bool</td>
<td>Whether or not to perform binary LDA. Default is multi-class LDA (i.e., distance metric learning).</td>
</tr>
<tr>
<td>normalize</td>
<td>bool</td>
<td>For binary LDA, whether or not to z-score normalize projection.</td>
</tr>
</tbody>
</table>
</li>
</ul>
<hr />
<h1 id="linear">Linear</h1>
<p>Wraps LibLinear's Linear SVM framework.</p>
<ul>
<li><strong>file:</strong> classification/liblinear.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/transform/transform/">Transform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/sklum" title="Scott J. Klum scott.klum@gmail.com">Scott Klum</a></li>
<li><strong>properties:</strong> None</li>
</ul>
<hr />
<h1 id="mlptransform">MLPTransform</h1>
<p>Wraps OpenCV's multi-layer perceptron framework</p>
<ul>
<li><strong>file:</strong> classification/mlp.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/metatransform/metatransform/">MetaTransform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/sklum" title="Scott J. Klum scott.klum@gmail.com">Scott Klum</a></li>
<li><strong>see:</strong> <a href="http://docs.opencv.org/modules/ml/doc/neural_networks.html"></a></li>
<li>
<p><strong>properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>kernel</td>
<td>enum</td>
<td>Type of MLP kernel to use. Options are Identity, Sigmoid, Gaussian. Default is Sigmoid.</td>
</tr>
<tr>
<td>alpha</td>
<td>float</td>
<td>Determines activation function for neural network. See OpenCV documentation for more details. Default is 1.</td>
</tr>
<tr>
<td>beta</td>
<td>float</td>
<td>Determines activation function for neural network. See OpenCV documentation for more details. Default is 1.</td>
</tr>
<tr>
<td>inputVariables</td>
<td>QStringList</td>
<td>Metadata keys for the labels associated with each template. There should be the same number of keys in the list as there are neurons in the final layer. Default is QStringList().</td>
</tr>
<tr>
<td>outputVariables</td>
<td>QStringList</td>
<td>Metadata keys to store the output of the neural network. There should be the same number of keys in the list as there are neurons in the final layer. Default is QStringList().</td>
</tr>
<tr>
<td>neuronsPerLayer</td>
<td>QList<int></td>
<td>The number of neurons in each layer of the net. Default is QList<int>() &lt;&lt; 1 &lt;&lt; 1.</td>
</tr>
</tbody>
</table>
</li>
</ul>
<hr />
<h1 id="nt4compare">NT4Compare</h1>
<p>Compare templates with Neurotech SDK 4</p>
<ul>
<li><strong>file:</strong> classification/nt4.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/distance/distance/">Distance</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/jklontz" title="Joshua C. Klontz, jklontz@ieee.org">Josh Klontz</a>, <a href="https://github.com/mmtaborsky" title="M. M. Taborsky mmtaborsky@gmail.com">E. Taborsky</a></li>
<li><strong>properties:</strong> None</li>
</ul>
<hr />
<h1 id="nt4detectface">NT4DetectFace</h1>
<p>Neurotech face detection</p>
<ul>
<li><strong>file:</strong> classification/nt4.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/untrainabletransform/untrainabletransform/">UntrainableTransform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/jklontz" title="Joshua C. Klontz, jklontz@ieee.org">Josh Klontz</a>, <a href="https://github.com/mmtaborsky" title="M. M. Taborsky mmtaborsky@gmail.com">E. Taborsky</a></li>
<li><strong>properties:</strong> None</li>
</ul>
<hr />
<h1 id="nt4enrollface">NT4EnrollFace</h1>
<p>Enroll face in Neurotech SDK 4</p>
<ul>
<li><strong>file:</strong> classification/nt4.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/untrainabletransform/untrainabletransform/">UntrainableTransform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/jklontz" title="Joshua C. Klontz, jklontz@ieee.org">Josh Klontz</a></li>
<li><strong>properties:</strong> None</li>
</ul>
<hr />
<h1 id="nt4enrolliris">NT4EnrollIris</h1>
<p>Enroll iris in Neurotech SDK 4</p>
<ul>
<li><strong>file:</strong> classification/nt4.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/untrainabletransform/untrainabletransform/">UntrainableTransform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/mmtaborsky" title="M. M. Taborsky mmtaborsky@gmail.com">E. Taborsky</a></li>
<li><strong>properties:</strong> None</li>
</ul>
<hr />
<h1 id="pcatransform">PCATransform</h1>
<p>Projects input into learned Principal Component Analysis subspace.</p>
<ul>
<li><strong>file:</strong> classification/lda.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/transform/transform/">Transform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/bklare" title="Dr. Brendan F. Klare brendan.klare@ieee.org">Brendan Klare</a>, <a href="https://github.com/jklontz" title="Joshua C. Klontz, jklontz@ieee.org">Josh Klontz</a></li>
<li>
<p><strong>properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>keep</td>
<td>float</td>
<td>Options are:<ul><li>keep &lt; 0 - All eigenvalues are retained</li><li>keep == 0 - No PCA is performed and the eigenvectors form an identity matrix</li><li>0 &lt; keep &lt; 1 - Keep is the fraction of the variance to retain</li><li>keep &gt;= 1 - keep is the number of leading eigenvectors to retain</li></ul>Default is 0.95.</td>
</tr>
<tr>
<td>drop</td>
<td>int</td>
<td>The number of leading eigen-dimensions to drop.</td>
</tr>
<tr>
<td>whiten</td>
<td>bool</td>
<td>Whether or not to perform PCA whitening (i.e., normalize variance of each dimension to unit norm)</td>
</tr>
</tbody>
</table>
</li>
</ul>
<hr />
<h1 id="pp4compare">PP4Compare</h1>
<p>Compare faces using PittPatt 4.</p>
<ul>
<li><strong>file:</strong> classification/pp4.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/distance/distance/">Distance</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/jklontz" title="Joshua C. Klontz, jklontz@ieee.org">Josh Klontz</a></li>
<li><strong>properties:</strong> None</li>
</ul>
<hr />
<h1 id="pp4enrolltransform">PP4EnrollTransform</h1>
<p>Enroll faces in PittPatt 4</p>
<ul>
<li><strong>file:</strong> classification/pp4.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/untrainablemetatransform/untrainablemetatransform/">UntrainableMetaTransform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/jklontz" title="Joshua C. Klontz, jklontz@ieee.org">Josh Klontz</a></li>
<li>
<p><strong>properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>detectOnly</td>
<td>bool</td>
<td>If true, return all detected faces. Otherwise, return only faces that are suitable for recognition. Default is false.</td>
</tr>
</tbody>
</table>
</li>
</ul>
<hr />
<h1 id="pp5comparedistance">PP5CompareDistance</h1>
<p>Compare templates with PP5. PP5 distance is known to be asymmetric</p>
<ul>
<li><strong>file:</strong> classification/pp5.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/untrainabledistance/untrainabledistance/">UntrainableDistance</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/jklontz" title="Joshua C. Klontz, jklontz@ieee.org">Josh Klontz</a>, <a href="https://github.com/mmtaborsky" title="M. M. Taborsky mmtaborsky@gmail.com">E. Taborsky</a></li>
<li><strong>properties:</strong> None</li>
</ul>
<hr />
<h1 id="pp5enrolltransform">PP5EnrollTransform</h1>
<p>Enroll faces in PP5</p>
<ul>
<li><strong>file:</strong> classification/pp5.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/untrainablemetatransform/untrainablemetatransform/">UntrainableMetaTransform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/jklontz" title="Joshua C. Klontz, jklontz@ieee.org">Josh Klontz</a>, <a href="https://github.com/mmtaborsky" title="M. M. Taborsky mmtaborsky@gmail.com">E. Taborsky</a></li>
<li>
<p><strong>properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>detectOnly</td>
<td>bool</td>
<td>If true, enroll all detected faces. Otherwise, only enroll faces suitable for recognition. Default is false.</td>
</tr>
<tr>
<td>requireLandmarks</td>
<td>bool</td>
<td>If true, require the right eye, left eye, and nose base to be detectable by PP5. If this does not happen FTE is set to true for that template. Default is false.</td>
</tr>
<tr>
<td>adaptiveMinSize</td>
<td>float</td>
<td>The minimum face size as a percentage of total image width. 0.1 corresponds to a minimum face size of 10% the total image width. Default is 0.01.</td>
</tr>
<tr>
<td>minSize</td>
<td>int</td>
<td>The absolute minimum face size to search for. This is not a pixel value. Please see PittPatt documentation for the relationship between minSize and pixel IPD. Default is 4.</td>
</tr>
<tr>
<td>landmarkRange</td>
<td>enum</td>
<td>Range of landmarks to search for. Options are Frontal, Extended, Full, and Comprehensive. Default is Comprehensive.</td>
</tr>
<tr>
<td>searchPruningAggressiveness</td>
<td>int</td>
<td>The amount of aggressiveness involved in search for faces in images. 0 means all scales and locations are searched. 1 means fewer detectors are used in the early stages but all scales are still searched. 2-4 means that the largest faces are found first and then fewer scales are searched. Default is 0.</td>
</tr>
</tbody>
</table>
</li>
</ul>
<hr />
<h1 id="pp5gallerytransform">PP5GalleryTransform</h1>
<p>DOCUMENT ME</p>
<ul>
<li><strong>file:</strong> classification/pp5.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/untrainablemetatransform/untrainablemetatransform/">UntrainableMetaTransform</a></li>
<li><strong>author(s):</strong> <a href="https://openbiometrics.com">Unknown</a></li>
<li><strong>properties:</strong> None</li>
</ul>
<hr />
<h1 id="svmtransform">SVMTransform</h1>
<p>Wraps OpenCV's SVM framework.</p>
<ul>
<li><strong>file:</strong> classification/svm.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/transform/transform/">Transform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/jklontz" title="Joshua C. Klontz, jklontz@ieee.org">Josh Klontz</a></li>
<li><strong>see:</strong> <a href="http://docs.opencv.org/modules/ml/doc/support_vector_machines.html"></a></li>
<li>
<p><strong>read:</strong></p>
<ol>
<li><em>C. Burges.</em><br>
 <strong>"A tutorial on support vector machines for pattern recognition"</strong>
 Knowledge Discovery and Data Mining 2(2), 1998.</li>
</ol>
</li>
<li>
<p><strong>properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Kernel</td>
<td>enum</td>
<td>The type of SVM kernel to use. Options are Linear, Poly, RBF, Sigmoid. Default is Linear.</td>
</tr>
<tr>
<td>Type</td>
<td>enum</td>
<td>The type of SVM to do. Options are C_SVC, NU_SVC, ONE_CLASS, EPS_SVR, NU_SVR. Default is C_SVC.</td>
</tr>
<tr>
<td>C</td>
<td>float</td>
<td>Parameter C of an SVM optimization problem. Needed when Type is C_SVC, EPS_SVR or NU_SVR. Default is -1.</td>
</tr>
<tr>
<td>gamma</td>
<td>float</td>
<td>Parameter gamma of a kernel function. Needed when Kernel is Poly, RBF, or Sigmoid. Default is -1.</td>
</tr>
<tr>
<td>inputVariable</td>
<td>QString</td>
<td>Metadata variable storing the label for each template. Default is "Label".</td>
</tr>
<tr>
<td>outputVariable</td>
<td>QString</td>
<td>Metadata variable to store the prediction value of the trained SVM. If type is EPS_SVR or NU_SVR the stored value is the output of the SVM. Otherwise the value is the output of the SVM mapped through the reverse lookup table. Default is "".</td>
</tr>
<tr>
<td>returnDFVal</td>
<td>bool</td>
<td>If true, dst is set to a 1x1 Mat with value equal to the predicted output of the SVM. Default is false.</td>
</tr>
<tr>
<td>termCriteria</td>
<td>int</td>
<td>The maximum number of training iterations. Default is 1000.</td>
</tr>
<tr>
<td>folds</td>
<td>int</td>
<td>Cross validation parameter used for autoselecting other parameters. Default is 5.</td>
</tr>
<tr>
<td>balanceFolds</td>
<td>bool</td>
<td>If true and the problem is 2-class classification then more balanced cross validation subsets are created. Default is false.</td>
</tr>
</tbody>
</table>
</li>
</ul>
<hr />
<h1 id="sparseldatransform">SparseLDATransform</h1>
<p>Projects input into learned Linear Discriminant Analysis subspace learned on a sparse subset of features with the highest weight in the original LDA algorithm.</p>
<ul>
<li><strong>file:</strong> classification/lda.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/transform/transform/">Transform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/bklare" title="Dr. Brendan F. Klare brendan.klare@ieee.org">Brendan Klare</a></li>
<li>
<p><strong>properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>varThreshold</td>
<td>float</td>
<td>BRENDAN FILL ME IN. Default is 1.5.</td>
</tr>
<tr>
<td>pcaKeep</td>
<td>float</td>
<td>BRENDAN FILL ME IN. Default is 0.98.</td>
</tr>
<tr>
<td>normalize</td>
<td>bool</td>
<td>BRENDAN FILL ME IN. Default is true.</td>
</tr>
</tbody>
</table>
</li>
</ul>
<hr />
<h1 id="turkclassifiertransform">TurkClassifierTransform</h1>
<p>Convenience class for training turk attribute regressors</p>
<ul>
<li><strong>file:</strong> classification/turk.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/transform/transform/">Transform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/jklontz" title="Joshua C. Klontz, jklontz@ieee.org">Josh Klontz</a></li>
<li>
<p><strong>properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>key</td>
<td>QString</td>
<td>Metadata key to pass input values to SVM. Actual lookup key is "key_value" where value is each value in the parameter values. Default is "".</td>
</tr>
<tr>
<td>values</td>
<td>QStringList</td>
<td>Metadata keys to pass input values to SVM. Actual lookup key is "key_value" where key is the parameter key and value is each value in this list. Each passed value trains a new SVM with the input values found in metadata<ul><li>"key_value"</li></ul>. Default is "".</td>
</tr>
<tr>
<td>isMeta</td>
<td>bool</td>
<td>If true, "Average+SaveMat(predicted_key_value)" is appended to each classifier. If false, nothing is appended. Default is false.</td>
</tr>
</tbody>
</table>
</li>
</ul>
<hr />
<h1 id="wcdatransform">WCDATransform</h1>
<p>Projects input into a within-class minimizing subspace.</p>
<p>Like LDA but without the explicit between-class consideration.</p>
<p>Note on Compression:
Projection matricies can become quite large, resulting in proportionally large model files.
WCDA automatically alleviates this issue with lossy compression of the projection matrix.
Each element is stored as an 8-bit integer instead of a 32-bit float, resulting in a 75% reduction in the size of the projection matrix.
A non-linear (sqrt) scaling is used because element values are distributed around 0, in affect allowing for higher precision storage of the more frequently occuring values.</p>
<ul>
<li><strong>file:</strong> classification/lda.cpp</li>
<li><strong>inherits:</strong> <a href="../../api_docs/cpp_api/transform/transform/">Transform</a></li>
<li><strong>author(s):</strong> <a href="https://github.com/jklontz" title="Joshua C. Klontz, jklontz@ieee.org">Josh Klontz</a></li>
<li><strong>properties:</strong> None</li>
</ul>
<hr />
<!-- Contributors -->
                            
                        </div>
                    </div>
                </div>
            </div>

        </section>
    </div>
</body>
</html>
